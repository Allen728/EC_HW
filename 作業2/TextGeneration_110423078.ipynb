{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-110423078_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "> **把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce89a572-7404-4cfd-fa90-abf004eafe40"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非學術用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "# 太多人同時存取可能會報cannot retrieve file error\n",
        "# 點擊you may still be able to access 下面那個連結再自行上傳檔案即可\n",
        "\n",
        "!gdown --id 1gMpt0CdlPjr1cR3HwDqumeKaucrSYhhe --output \"./Eileen_Legendary.txt\"\n",
        "\n",
        "# !wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gMpt0CdlPjr1cR3HwDqumeKaucrSYhhe\n",
            "To: /content/Eileen_Legendary.txt\n",
            "100% 818k/818k [00:00<00:00, 164MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mbvzh_9_Tz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a939ac4-14aa-438b-aed3-d4ffbc1fd7bd"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"./Eileen_Legendary.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"張愛玲散文集共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "張愛玲散文集共有 274000 字詞\n",
            "包含了 3665 個獨一無二的字 (含標點符號)\n",
            "\n",
            "我自己從來沒想到需要辯白，但最近一年來常常被人議論到，似乎被列為文化漢奸之一，自己也弄得莫名其妙。我所寫的文章從來沒有涉及政治，也沒有拿過任何津貼。想想看我唯一的嫌疑要末就是所謂「大東亞文學者大會」第三屆曾經叫我參加，報上登出的名單內有我；雖然我寫了辭函去，（那封信我還記得，因為很短，僅只是：「承聘為第三屆大東亞文學者大會代表，謹辭。張愛玲謹上。」）報上仍舊沒有把名字去掉。\n",
            "至於還有許多無稽的謾罵，甚而涉及我的私生活，可以辯駁之點本來非常多。而且即使有這種事實，也還牽涉不到我是否有漢奸嫌疑的問題；何況私人的事本來用不著向大眾剖白，除了對自己家的家長之外彷彿我沒有解釋的義務。所以一直緘默著。同時我也實在不願意耗費時間與精神去打筆墨官司，徒然攪亂心思，耽誤了正當的工作。但一直這樣沉默著，始終沒有闡明我的地位，給社會上一個錯誤的印象，我也覺得是對不起關心我的前途的人。所以在小說集重印的時候寫了這樣一段作為序。反正只要讀者知道了就是了。\n",
            "※※※\n",
            "《傳奇》裏面新收進的五篇，「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」，初發表的時候有許多草率的地方，實在對讀者感到抱歉，這次\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT90O679Fe0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b95abb-11e0-49b1-f601-5be8708e9ad7"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去除次數小於8的文字剩餘 : 1973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_uP5gOVIy2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68712ac9-52cd-4832-e1fc-1cbe26da9b8f"
      },
      "source": [
        "print(f\"原本張愛玲散文集共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本張愛玲散文集共有 274000 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘268660個字\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LP0BwFDAmcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900bdf8d-96ef-49ff-9c34-317b0e2c61cc"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始文字 : \n",
            "['我', '自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常', '常', '被', '人', '議', '論', '到', '，', '似', '乎', '被', '列', '為', '文', '化', '漢', '之', '一', '，', '自', '己']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{1921, 1540, 1799, 1929, 1937, 659, 1428, 1558, 1053, 1954, 1955, 1188, 1958, 1968, 178, 1972, 1854, 1730, 1731, 1618, 1876, 1885, 1890, 1891, 1636, 99, 614, 1646, 1905, 1907, 1781}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aDyjJymDmVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefc62ea-5258-43e7-d8cf-bdf518325f71"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[1954 1907 1876 1854 1958 1929 1890 1937  659 1921  614 1891 1972 1730\n",
            " 1636 1558 1968 1885 1958 1731 1731], shape=(21,), dtype=int32)\n",
            "['我', '自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常', '常']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[1646 1955 1053 1428 1937 1972 1799 1540 1646   99 1905 1618 1188  178\n",
            " 1781 1968 1972 1907 1876 1942 1470], shape=(21,), dtype=int32)\n",
            "['被', '人', '議', '論', '到', '，', '似', '乎', '被', '列', '為', '文', '化', '漢', '之', '一', '，', '自', '己', '也', '弄']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhFC16MdLONw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a708c68f-542f-4a31-9d7d-0636af8f418a"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnJ4Bdj2gZ1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1922d3d4-c4ca-4309-f2bd-3d5f60be9c28"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : ['我', '自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常']\n",
            "Target: ['自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常', '常']\n",
            "--------------------------------------------------\n",
            "Input : [1954 1907 1876 1854 1958 1929 1890 1937  659 1921  614 1891 1972 1730\n",
            " 1636 1558 1968 1885 1958 1731]\n",
            "Target: [1907 1876 1854 1958 1929 1890 1937  659 1921  614 1891 1972 1730 1636\n",
            " 1558 1968 1885 1958 1731 1731]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNivSh2Igr2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e40698-d55a-4db8-97e7-00358dd3d3d9"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkRcSZAHnxlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55682a6c-645d-4582-d3aa-a46a38be287e"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 512)         1010176   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 1973)        4042677   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,906,549\n",
            "Trainable params: 130,906,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKiszF5doFGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384e3507-60e5-4904-d0f7-1a4b9b41930d"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 1973)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsN6Zz4NReV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c605af17-41b3-47ba-fb38-7bb7fc8f8d5b"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "濟的關係嗎？」梁太太答道：「他並不是沒有\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "衫章職摘繼廊偶偶余余謂謂謂謂誰誰封封��\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IW5xiiMpJhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f2f15f-853d-4a01-cf28-a65b056a1fc8"
      },
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "199/199 [==============================] - 64s 306ms/step - loss: 6.0177\n",
            "Epoch 2/10\n",
            "199/199 [==============================] - 65s 322ms/step - loss: 5.2913\n",
            "Epoch 3/10\n",
            "199/199 [==============================] - 67s 335ms/step - loss: 4.8105\n",
            "Epoch 4/10\n",
            "199/199 [==============================] - 68s 338ms/step - loss: 4.4960\n",
            "Epoch 5/10\n",
            "199/199 [==============================] - 68s 337ms/step - loss: 4.2614\n",
            "Epoch 6/10\n",
            "199/199 [==============================] - 67s 337ms/step - loss: 4.0570\n",
            "Epoch 7/10\n",
            "199/199 [==============================] - 67s 337ms/step - loss: 3.8503\n",
            "Epoch 8/10\n",
            "199/199 [==============================] - 67s 337ms/step - loss: 3.6280\n",
            "Epoch 9/10\n",
            "199/199 [==============================] - 67s 337ms/step - loss: 3.3786\n",
            "Epoch 10/10\n",
            "199/199 [==============================] - 67s 337ms/step - loss: 3.0846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1847f9dc-21c0-430d-b74c-5816c9027cd8"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3elbMNg4z4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7be737-ca67-4f0a-8fac-44590bd90ce6"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "濟的關係嗎？」梁太太答道：「他並不是沒有\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "的，係嗎？」\n",
            "太太道道：「你不不是不有錢\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90f95d7-c44a-48ee-de78-51ce2e9b47e0"
      },
      "source": [
        "init_seq = \"紅玫瑰\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "紅玫瑰，一個姿樂，蕊切地粹著一點水，瞅著她的一個印度的房子，處顏色的，像是澤的，致著一點，送了一個字，又是一個窩子。\n",
            "資鸝求到了，她做不著，因為盧兆麟躊躇的家庭，她和他們的遠體的一個撒號的季節，齡公館裏的燈光，仔細是一個敦鳳的嬤節。她怎麼能夠使人能夠相信，她缺釋地說：「你別以為你現在的時候，你有個人，你喳帳上的女兒，你們還有一個不要緊的人。」\n",
            "小寒道：「你不知道，我不是不知道，我們莫問我們對於你的。」\n",
            "小寒道：「你不知道，我不是不知道，我就是這樣的！」\n",
            "小寒道：「你不知道，我任果沒有層意。」\n",
            "小寒道：「你不知道，我們到底是怎麼樣的一個人？」\n",
            "小寒道：「你不知道，我沒有這麼一個人。」\n",
            "小寒道：「你當心嗅著你的媒，你梁太太你也不是那樣的人！」\n",
            "小寒道：「不知道，不是我說的。」\n",
            "小寒道：「不知道，我就是不篤保的節思。」\n",
            "小寒道：「你不知道，我們戰了這個，默不得，我也不懂得。」\n",
            "小寒道：「你不知道，我趁不到我們那兒去。」\n",
            "小寒道：「你不知道，我絹皮兒戶的難得聽見。」\n",
            "小寒道：「我不知道，我列著這個不好，我們不能夠干涉！」\n",
            "小寒道：「我不知道，我血待你不知道，我們掛著這個時候，我嫌你的，你肉能夠驗的。"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "source": [
        "# 不要執行這一個block\n",
        "# import time\n",
        "# while True:\n",
        "#   time.sleep(5)\n",
        "#   pass"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d472a166-277f-43ac-8272-be98551a813f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fz9V-KKmJnWQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book = \"\"\n",
        "with open(\"/content/gdrive/MyDrive/NCU/HW2/哈利波特1神秘的魔法石.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"哈利波特1-神秘的魔法石 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "metadata": {
        "id": "QGp-TR08Jzps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7662061d-dec8-458c-cbeb-9b639859a627"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "哈利波特1-神秘的魔法石 156198 字詞\n",
            "包含了 2858 個獨一無二的字 (含標點符號)\n",
            "\n",
            "第１章 大難不死的男孩\n",
            "家住水蠟樹街四號的德思禮夫婦總是得意地說他們是非常規矩的人家。拜託，拜託了。他們從來跟神秘古怪的事不沾邊，因為他們根本不相信那些邪門歪道。\n",
            "威農德思禮先生在一家名叫格朗寧的公司做主管，公司生產鑽機。他高大魁梧，胖得幾乎連脖子都沒了，卻蓄著一臉大鬍子。德思禮太太是個瘦削的金髮女人。她的脖子幾乎比正常人長一倍。這樣每當她花許多時間隔著籬牆引頸而望、窺探左鄰右舍時，她的長脖子可就派上了大用場。德思禮夫婦有一個小兒子，名叫達力。在他們看來，人世間沒有比達力更好的孩子了。\n",
            "德思禮一家什麼都不缺，但他們擁有一個秘密，他們最害怕的就是這秘密會被人發現。他們想，一旦有人發現波特一家的事，他們會承受不住的。波特太太是德思禮太太的妹妹，不過她們已經有好幾年不見面了。實際上，德思禮太太佯裝自己根本沒有這麼個妹妹，因為她妹妹和她那一無是處的妹夫與德思禮一家的為人處世完全不一樣。一想到鄰居們會說波特夫婦來到了，德思禮夫婦會嚇得膽顫心驚。他們知道波特也有個兒子，只是他們從來沒有見過。這孩子也是他們不與波特夫婦來往的一個很好的藉口，他們不願讓達力跟這種孩子廝混。\n",
            "我們的故事開始於一個晦暗、陰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "metadata": {
        "id": "qKaYdrs7J2gE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "metadata": {
        "id": "WqCzmB9-J4_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e5ca63-7fdf-4c81-c916-4f305fbef0db"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去除次數小於8的文字剩餘 : 1375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"原本哈利波特共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "metadata": {
        "id": "PmJAoEcaJ6eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c76c16-40e2-4c21-9611-3846c9a2fcaa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本哈利波特共有 156198 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘151496個字\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "metadata": {
        "id": "C0riVVlhJ8kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e8b572-c632-46ee-f218-cd7074a795e4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始文字 : \n",
            "['第', '章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的', '德', '思', '禮', '夫', '婦', '總', '是', '得', '意', '地', '說', '他', '們', '是', '非', '常', '規', '的', '人', '家']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{1176, 1180, 1186, 1187, 809, 683, 1069, 1333, 695, 1337, 1342, 1220, 1094, 969, 1354, 1101, 1358, 1105, 978, 1362, 1364, 1365, 1370, 1242, 1372, 1371, 1118, 1123, 486, 1254, 487, 872, 1258, 1133, 888, 1150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "metadata": {
        "id": "rZkkm4AdJ_iQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "metadata": {
        "id": "hZcXxdGHKA9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12116e60-4992-4c88-aafc-95dc9abacc3d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[1180  486  888 1337 1094 1365 1133 1372 1123 1101 1370 1254 1258  978\n",
            "  487  969  872 1069  695 1372 1176], shape=(21,), dtype=int32)\n",
            "['第', '章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的', '德']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[1220 1186 1187  809 1118 1364 1333 1242 1354 1358 1371 1362 1364 1105\n",
            " 1150  683 1372 1342 1254 1373 1374], shape=(21,), dtype=int32)\n",
            "['思', '禮', '夫', '婦', '總', '是', '得', '意', '地', '說', '他', '們', '是', '非', '常', '規', '的', '人', '家', '。', '，']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "id": "NMdjkBciKCoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6ec0d7-512c-49de-df4e-54eac7c2760f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "metadata": {
        "id": "ELtRtGYBKIrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b5f0ea-cb9f-4a0c-a4c9-766c093eaf72"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : ['第', '章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的']\n",
            "Target: ['章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的', '德']\n",
            "--------------------------------------------------\n",
            "Input : [1180  486  888 1337 1094 1365 1133 1372 1123 1101 1370 1254 1258  978\n",
            "  487  969  872 1069  695 1372]\n",
            "Target: [ 486  888 1337 1094 1365 1133 1372 1123 1101 1370 1254 1258  978  487\n",
            "  969  872 1069  695 1372 1176]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "Jy35err0KKSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414dd82a-ad96-45f0-9d59-4fa991983dcb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "AnTW1WB9KMgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce9b1e6-3946-4ed8-84a0-9f37dd7d3e88"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 512)         704000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, None, 1375)        2817375   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 129,375,071\n",
            "Trainable params: 129,375,071\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "metadata": {
        "id": "c_DbUdgIKOGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040421e0-9992-4733-9211-41691858b706"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 1375)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "metadata": {
        "id": "x2NwK8LkKPtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c957f40f-15ca-463b-d5d8-3d8926b9b71c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "，大喊大叫，連帶跳往後退去。\n",
            "哈利坐起來\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "冰冰冰冰讀讀讀讀讀讀讀讀讀妙妙答彿父彿彿\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "blfZn7laKRN1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "metadata": {
        "id": "fRPZTUHKKbaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1597d9d-3a6a-4d9d-fca6-953a524c80df"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "112/112 [==============================] - 36s 296ms/step - loss: 6.0350\n",
            "Epoch 2/20\n",
            "112/112 [==============================] - 35s 307ms/step - loss: 5.2886\n",
            "Epoch 3/20\n",
            "112/112 [==============================] - 36s 322ms/step - loss: 4.7693\n",
            "Epoch 4/20\n",
            "112/112 [==============================] - 37s 324ms/step - loss: 4.3845\n",
            "Epoch 5/20\n",
            "112/112 [==============================] - 38s 332ms/step - loss: 4.0908\n",
            "Epoch 6/20\n",
            "112/112 [==============================] - 37s 332ms/step - loss: 3.8429\n",
            "Epoch 7/20\n",
            "112/112 [==============================] - 38s 335ms/step - loss: 3.6044\n",
            "Epoch 8/20\n",
            "112/112 [==============================] - 38s 333ms/step - loss: 3.3495\n",
            "Epoch 9/20\n",
            "112/112 [==============================] - 38s 335ms/step - loss: 3.0738\n",
            "Epoch 10/20\n",
            "112/112 [==============================] - 38s 335ms/step - loss: 2.7570\n",
            "Epoch 11/20\n",
            "112/112 [==============================] - 38s 333ms/step - loss: 2.3906\n",
            "Epoch 12/20\n",
            "112/112 [==============================] - 38s 335ms/step - loss: 1.9779\n",
            "Epoch 13/20\n",
            "112/112 [==============================] - 38s 334ms/step - loss: 1.5338\n",
            "Epoch 14/20\n",
            "112/112 [==============================] - 38s 334ms/step - loss: 1.0889\n",
            "Epoch 15/20\n",
            "112/112 [==============================] - 38s 334ms/step - loss: 0.7213\n",
            "Epoch 16/20\n",
            "112/112 [==============================] - 38s 336ms/step - loss: 0.4806\n",
            "Epoch 17/20\n",
            "112/112 [==============================] - 38s 333ms/step - loss: 0.3560\n",
            "Epoch 18/20\n",
            "112/112 [==============================] - 38s 335ms/step - loss: 0.2984\n",
            "Epoch 19/20\n",
            "112/112 [==============================] - 38s 334ms/step - loss: 0.2720\n",
            "Epoch 20/20\n",
            "112/112 [==============================] - 38s 335ms/step - loss: 0.2593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bO-6II0RKgG2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "092843cf-274a-4abe-f8e4-835b4be6bfaf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "metadata": {
        "id": "rMr8bU7CKmO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda145e6-b51d-40d8-8d84-868cb3a5501c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "，大喊大叫，連帶跳往後退去。\n",
            "哈利坐起來\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "「喊大叫，連帶跳往後退去。\n",
            "哈利坐起來，\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "metadata": {
        "id": "kYgR_i9kKn-V"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_seq = \"哈利波特\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "metadata": {
        "id": "mPph85H2KqJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba28634e-e95f-41e9-ecb7-bb8649150cab"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "哈利波特！」\n",
            "他的心突然往下一沉，比他剛才出來了，他的生日裡還有一個再躲。」\n",
            "「我就把你留在這兒吧，」哈利說，「我們必須充當棋子。」\n",
            "「我不知道，先生。」\n",
            "「我不知道它叫這個名字，先生。」海格說。\n",
            "「我不是弗雷，我不知道你是誰了！」\n",
            "「我想，我們一定離來了。」\n",
            "「不管怎麼說……哈利，」巨蟒說，「你們可以肯定一定是學校裡的學院。我們需要學習的東西太多，就把隱形斗篷送給你的。」\n",
            "「我……不想……穿……」\n",
            "「別大聲嚷嚷，」他說，「我們必須充當棋子。」\n",
            "「我不知道，先生。」\n",
            "「我不知道它叫這個名字，先生。」海格說著，舉起望遠鏡，巨蟒從他們身邊走過去。\n",
            "「好，」海格說，「裏邊是魁地奇球的是爆，」他們把隱形斗篷拉在身上。\n",
            "「我們還是回家去比好，」他對著一隻子住前，佩妮阿姨說服達力坐到哈利身邊，想看這裡就是個盼望。\n",
            "哈利覺得自己臉上頓時失去了血跡。\n",
            "「……他還是有一個秘密。」\n",
            "「我們只能猜測，」哈利說，「幸吧，我們現在必須這麼做，」鄧不利多說，「我們不知道這個洞有多深。把笛子給你們，想要在霍格華茲魔法學校就讀。隨信很強，我們需要一個人，這是一個好。」\n",
            "「哦，」男孩說，「我聽說過這個洞有不同的動物，可是你們在"
          ]
        }
      ]
    }
  ]
}